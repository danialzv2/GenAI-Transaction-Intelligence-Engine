{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06375bd2",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d8f4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a banking transaction explanation assistant.\n",
    "\n",
    "Rules:\n",
    "- Explain ONLY using the provided facts.\n",
    "- Do NOT add new information.\n",
    "- Do NOT speculate about user intent.\n",
    "- Do NOT provide financial advice.\n",
    "- Keep explanations factual and concise.\n",
    "- Maximum 3 sentences.\n",
    "\"\"\"\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\"\n",
    "Explain the following transaction insight in clear, human-friendly language.\n",
    "\n",
    "Insight Type: {insight_type}\n",
    "Severity: {severity}\n",
    "Facts:\n",
    "{facts}\n",
    "\n",
    "Explanation:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4309199",
   "metadata": {},
   "source": [
    "### Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c60ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72cb295",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"\n",
    "MODEL_NAME = \"llama3.1:8b\"\n",
    "\n",
    "INSIGHT_FILE = \"../data/transaction_insights.json\"\n",
    "OUTPUT_FILE = \"../data/transaction_explanations.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1c8a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanation(insight):\n",
    "    facts_text = \"\\n\".join(\n",
    "        [f\"- {k}: {v}\" for k, v in insight[\"facts\"].items()]\n",
    "    )\n",
    "\n",
    "    prompt = USER_PROMPT_TEMPLATE.format(\n",
    "        insight_type=insight[\"insight_type\"],\n",
    "        severity=insight[\"severity\"],\n",
    "        facts=facts_text\n",
    "    )\n",
    "\n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": f\"{SYSTEM_PROMPT}\\n{prompt}\",\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"temperature\": 0.2,\n",
    "            \"num_predict\": 120\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = requests.post(OLLAMA_URL, json=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    return response.json()[\"response\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "525e04f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local LLaMA explanations generated → ../data/transaction_explanations.json\n"
     ]
    }
   ],
   "source": [
    "with open(INSIGHT_FILE) as f:\n",
    "    insights = json.load(f)\n",
    "\n",
    "explanations = []\n",
    "\n",
    "for insight in insights:\n",
    "    explanation = generate_explanation(insight)\n",
    "\n",
    "    explanations.append({\n",
    "        \"transaction_id\": insight[\"transaction_id\"],\n",
    "        \"insight_type\": insight[\"insight_type\"],\n",
    "        \"explanation\": explanation\n",
    "    })\n",
    "\n",
    "with open(OUTPUT_FILE, \"w\") as f:\n",
    "    json.dump(explanations, f, indent=2)\n",
    "\n",
    "print(f\"Local LLaMA explanations generated → {OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011617f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
